# LLM-vicuna13B-webqa
This is an Vicuna-13B deployment with [GenRead](https://arxiv.org/abs/2209.10063) on [WebQA](https://webqna.github.io/) dataset. The evaluation script is not published by [WebQA](https://webqna.github.io/) so it's hard to tell the performance.

## Installation
1. Download the dataset from [WebQA](https://webqna.github.io/)
2. Follow the Model Weights section from [FastChat](https://github.com/lm-sys/FastChat)
3. Install the required package from requirement.txt(Ongoing)

## Usage
`./run_vicuna.sh`

## License
Please follow [Meta's LLaMA model license](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md)
